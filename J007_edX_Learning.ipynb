{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "J007_edX_Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOPKC4ruVJhI6zcpvEgRxsd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jash-Bhatia/AI_DS/blob/master/J007_edX_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YNboORqpgwQp"
      },
      "source": [
        "# **Machine Learning Module**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaesAQLnoOhm"
      },
      "source": [
        "## **NIM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1n2abEtGlCmO"
      },
      "source": [
        "import math\n",
        "import random\n",
        "import time"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HH2Yk6CrlCBN"
      },
      "source": [
        "\n",
        "class Nim():\n",
        "\n",
        "    def __init__(self, initial=[1, 3, 5, 7]):\n",
        "        \"\"\"\n",
        "        Initialize game board.\n",
        "        Each game board has\n",
        "            - `piles`: a list of how many elements remain in each pile\n",
        "            - `player`: 0 or 1 to indicate which player's turn\n",
        "            - `winner`: None, 0, or 1 to indicate who the winner is\n",
        "        \"\"\"\n",
        "        self.piles = initial.copy()\n",
        "        self.player = 0\n",
        "        self.winner = None\n",
        "\n",
        "    @classmethod\n",
        "    def available_actions(cls, piles):\n",
        "        \"\"\"\n",
        "        Nim.available_actions(piles) takes a `piles` list as input\n",
        "        and returns all of the available actions `(i, j)` in that state.\n",
        "        Action `(i, j)` represents the action of removing `j` items\n",
        "        from pile `i` (where piles are 0-indexed).\n",
        "        \"\"\"\n",
        "        actions = set()\n",
        "        for i, pile in enumerate(piles):\n",
        "            for j in range(1, piles[i] + 1):\n",
        "                actions.add((i, j))\n",
        "        return actions\n",
        "\n",
        "    @classmethod\n",
        "    def other_player(cls, player):\n",
        "        \"\"\"\n",
        "        Nim.other_player(player) returns the player that is not\n",
        "        `player`. Assumes `player` is either 0 or 1.\n",
        "        \"\"\"\n",
        "        return 0 if player == 1 else 1\n",
        "\n",
        "    def switch_player(self):\n",
        "        \"\"\"\n",
        "        Switch the current player to the other player.\n",
        "        \"\"\"\n",
        "        self.player = Nim.other_player(self.player)\n",
        "\n",
        "    def move(self, action):\n",
        "        \"\"\"\n",
        "        Make the move `action` for the current player.\n",
        "        `action` must be a tuple `(i, j)`.\n",
        "        \"\"\"\n",
        "        pile, count = action\n",
        "\n",
        "        # Check for errors\n",
        "        if self.winner is not None:\n",
        "            raise Exception(\"Game already won\")\n",
        "        elif pile < 0 or pile >= len(self.piles):\n",
        "            raise Exception(\"Invalid pile\")\n",
        "        elif count < 1 or count > self.piles[pile]:\n",
        "            raise Exception(\"Invalid number of objects\")\n",
        "\n",
        "        # Update pile\n",
        "        self.piles[pile] -= count\n",
        "        self.switch_player()\n",
        "\n",
        "        # Check for a winner\n",
        "        if all(pile == 0 for pile in self.piles):\n",
        "            self.winner = self.player"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCRIYUCRoqEW"
      },
      "source": [
        "class NimAI():\n",
        "\n",
        "    def __init__(self, alpha=0.5, epsilon=0.1):\n",
        "        \"\"\"\n",
        "        Initialize AI with an empty Q-learning dictionary,\n",
        "        an alpha (learning) rate, and an epsilon rate.\n",
        "        The Q-learning dictionary maps `(state, action)`\n",
        "        pairs to a Q-value (a number).\n",
        "         - `state` is a tuple of remaining piles, e.g. (1, 1, 4, 4)\n",
        "         - `action` is a tuple `(i, j)` for an action\n",
        "        \"\"\"\n",
        "        self.q = dict()\n",
        "        self.alpha = alpha\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def update(self, old_state, action, new_state, reward):\n",
        "        \"\"\"\n",
        "        Update Q-learning model, given an old state, an action taken\n",
        "        in that state, a new resulting state, and the reward received\n",
        "        from taking that action.\n",
        "        \"\"\"\n",
        "        old = self.get_q_value(old_state, action)\n",
        "        best_future = self.best_future_reward(new_state)\n",
        "        self.update_q_value(old_state, action, old, reward, best_future)\n",
        "\n",
        "    def get_q_value(self, state, action):\n",
        "        \"\"\"\n",
        "        Return the Q-value for the state `state` and the action `action`.\n",
        "        If no Q-value exists yet in `self.q`, return 0.\n",
        "        \"\"\"\n",
        "        return self.q[(tuple(state), action)] if (tuple(state), action) in self.q else 0\n",
        "\n",
        "    def update_q_value(self, state, action, old_q, reward, future_rewards):\n",
        "        \"\"\"\n",
        "        Update the Q-value for the state `state` and the action `action`\n",
        "        given the previous Q-value `old_q`, a current reward `reward`,\n",
        "        and an estiamte of future rewards `future_rewards`.\n",
        "        Use the formula:\n",
        "        Q(s, a) <- old value estimate\n",
        "                   + alpha * (new value estimate - old value estimate)\n",
        "        where `old value estimate` is the previous Q-value,\n",
        "        `alpha` is the learning rate, and `new value estimate`\n",
        "        is the sum of the current reward and estimated future rewards.\n",
        "        \"\"\"\n",
        "        self.q[(tuple(state), action)] = old_q + self.alpha * (future_rewards + reward - old_q)\n",
        "\n",
        "    def best_future_reward(self, state):\n",
        "        \"\"\"\n",
        "        Given a state `state`, consider all possible `(state, action)`\n",
        "        pairs available in that state and return the maximum of all\n",
        "        of their Q-values.\n",
        "        Use 0 as the Q-value if a `(state, action)` pair has no\n",
        "        Q-value in `self.q`. If there are no available actions in\n",
        "        `state`, return 0.\n",
        "        \"\"\"\n",
        "        best_reward = 0\n",
        "        actions = list(Nim.available_actions(state))\n",
        "        for action in actions:\n",
        "            best_reward = max(self.get_q_value(state, action), best_reward)\n",
        "        return best_reward\n",
        "\n",
        "    def choose_action(self, state, epsilon=True):\n",
        "        \"\"\"\n",
        "        Given a state `state`, return an action `(i, j)` to take.\n",
        "        If `epsilon` is `False`, then return the best action\n",
        "        available in the state (the one with the highest Q-value,\n",
        "        using 0 for pairs that have no Q-values).\n",
        "        If `epsilon` is `True`, then with probability\n",
        "        `self.epsilon` choose a random available action,\n",
        "        otherwise choose the best action available.\n",
        "        If multiple actions have the same Q-value, any of those\n",
        "        options is an acceptable return value.\n",
        "        \"\"\"\n",
        "        best_action = None\n",
        "        best_reward = 0\n",
        "        actions = list(Nim.available_actions(state))\n",
        "        for action in actions:\n",
        "            q_val = self.get_q_value(state, action)\n",
        "            if best_action is None or q_val > best_reward:\n",
        "                best_reward = q_val\n",
        "                best_action = action\n",
        "\n",
        "        if epsilon:\n",
        "            total_actions = len(actions)\n",
        "            weights = [(1 - self.epsilon) if action == best_action else self.epsilon for action in actions]\n",
        "            best_action = random.choices(actions, weights=weights, k=1)[0]\n",
        "\n",
        "        return best_action\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfXTH3B7oxsd"
      },
      "source": [
        "def train(n):\n",
        "    \"\"\"\n",
        "    Train an AI by playing `n` games against itself.\n",
        "    \"\"\"\n",
        "\n",
        "    player = NimAI()\n",
        "\n",
        "    # Play n games\n",
        "    for i in range(n):\n",
        "        print(f\"Playing training game {i + 1}\")\n",
        "        game = Nim()\n",
        "\n",
        "        # Keep track of last move made by either player\n",
        "        last = {\n",
        "            0: {\"state\": None, \"action\": None},\n",
        "            1: {\"state\": None, \"action\": None}\n",
        "        }\n",
        "\n",
        "        # Game loop\n",
        "        while True:\n",
        "\n",
        "            # Keep track of current state and action\n",
        "            state = game.piles.copy()\n",
        "            action = player.choose_action(game.piles)\n",
        "\n",
        "            # Keep track of last state and action\n",
        "            last[game.player][\"state\"] = state\n",
        "            last[game.player][\"action\"] = action\n",
        "\n",
        "            # Make move\n",
        "            game.move(action)\n",
        "            new_state = game.piles.copy()\n",
        "\n",
        "            # When game is over, update Q values with rewards\n",
        "            if game.winner is not None:\n",
        "                player.update(state, action, new_state, -1)\n",
        "                player.update(\n",
        "                    last[game.player][\"state\"],\n",
        "                    last[game.player][\"action\"],\n",
        "                    new_state,\n",
        "                    1\n",
        "                )\n",
        "                break\n",
        "\n",
        "            # If game is continuing, no rewards yet\n",
        "            elif last[game.player][\"state\"] is not None:\n",
        "                player.update(\n",
        "                    last[game.player][\"state\"],\n",
        "                    last[game.player][\"action\"],\n",
        "                    new_state,\n",
        "                    0\n",
        "                )\n",
        "\n",
        "    print(\"Done training\")\n",
        "\n",
        "    # Return the trained AI\n",
        "    return player"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZtnUFSDoyCS"
      },
      "source": [
        "def play(ai, human_player=None):    \n",
        "    \"\"\"\n",
        "    Play human game against the AI.\n",
        "    `human_player` can be set to 0 or 1 to specify whether\n",
        "    human player moves first or second.\n",
        "    \"\"\"\n",
        "\n",
        "    # If no player order set, choose human's order randomly\n",
        "    if human_player is None:\n",
        "        human_player = random.randint(0, 1)\n",
        "\n",
        "    # Create new game\n",
        "    game = Nim()\n",
        "\n",
        "    # Game loop\n",
        "    while True:\n",
        "\n",
        "        # Print contents of piles\n",
        "        print()\n",
        "        print(\"Piles:\")\n",
        "        for i, pile in enumerate(game.piles):\n",
        "            print(f\"Pile {i}: {pile}\")\n",
        "        print()\n",
        "\n",
        "        # Compute available actions\n",
        "        available_actions = Nim.available_actions(game.piles)\n",
        "        time.sleep(1)\n",
        "\n",
        "        # Let human make a move\n",
        "        if game.player == human_player:\n",
        "            print(\"Your Turn\")\n",
        "            while True:\n",
        "                pile = int(input(\"Choose Pile: \"))\n",
        "                count = int(input(\"Choose Count: \"))\n",
        "                if (pile, count) in available_actions:\n",
        "                    break\n",
        "                print(\"Invalid move, try again.\")\n",
        "\n",
        "        # Have AI make a move\n",
        "        else:\n",
        "            print(\"AI's Turn\")\n",
        "            pile, count = ai.choose_action(game.piles, epsilon=False)\n",
        "            print(f\"AI chose to take {count} from pile {pile}.\")\n",
        "\n",
        "        # Make move\n",
        "        game.move((pile, count))\n",
        "\n",
        "        # Check for winner\n",
        "        if game.winner is not None:\n",
        "            print()\n",
        "            print(\"GAME OVER\")\n",
        "            winner = \"Human\" if game.winner == human_player else \"AI\"\n",
        "            print(f\"Winner is {winner}\")\n",
        "            return\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcOUR3vhoyFo"
      },
      "source": [
        ""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6VfCf2uk7tj"
      },
      "source": [
        "## **Shopping**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nSgZsbDefz6"
      },
      "source": [
        "# importing libraries\n",
        "\n",
        "import csv\n",
        "import sys\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import DataFrame as dframe"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaBEWsmFg19s"
      },
      "source": [
        "#Defining main function\n",
        "\n",
        "def main(TEST_SIZE):\n",
        "    \n",
        "    # Load data from spreadsheet and split into train and test sets\n",
        "    evidence, labels = load_data(sys.argv[1])\n",
        "    X_train, X_test, y_train, y_test = train_test_split(evidence, labels, test_size=TEST_SIZE)\n",
        "    # Train model and make predictions\n",
        "    model = train_model(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    sensitivity, specificity = evaluate(y_test, predictions)\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Correct: {(y_test == predictions).sum()}\")\n",
        "    print(f\"Incorrect: {(y_test != predictions).sum()}\")\n",
        "    print(f\"True Positive Rate: {100 * sensitivity:.2f}%\")\n",
        "    print(f\"True Negative Rate: {100 * specificity:.2f}%\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRwoUf1Ng2Ar"
      },
      "source": [
        "# function to load data\n",
        "\n",
        "def load_data(filename):\n",
        "   \n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    filename = pd.read_csv('/Users/home/Downloads//shopping.csv')\n",
        "    df = filename\n",
        "    month = { 'Feb': 1, 'Mar': 2, 'May': 4, 'June':5, 'Jul':6, 'Aug':7, 'Sep': 8, 'Oct':9, 'Nov': 10, 'Dec': 11}\n",
        "    df.Month = [month[item] for item in df.Month]\n",
        "    vistype = { 'Returning_Visitor': 1, 'New_Visitor': 0, 'Other':0 }\n",
        "    df.VisitorType = [vistype[item] for item in df.VisitorType]\n",
        "    df['Weekend'] = df['Weekend']*1\n",
        "    df['Revenue'] = df['Revenue']*1\n",
        "    \n",
        "    evidence = df.drop(columns = 'Revenue')\n",
        "    \n",
        "    Administrative = np.array(evidence['Administrative'], dtype = int)\n",
        "    Administrative_Duration = np.array(evidence['Administrative_Duration'])\n",
        "    Informational = np.array(evidence['Informational'], dtype = int)\n",
        "    Informational_Duration = np.array(evidence['Informational_Duration'])\n",
        "    ProductRelated = np.array(evidence['ProductRelated'], dtype = int)\n",
        "    ProductRelated_Duration = np.array(evidence['ProductRelated_Duration'])\n",
        "    BounceRates = np.array(evidence['BounceRates'])\n",
        "    ExitRates = np.array(evidence['ExitRates'])\n",
        "    PageValues = np.array(evidence['PageValues'])\n",
        "    SpecialDay = np.array(evidence['SpecialDay'])\n",
        "    Month = np.array(evidence['Month'], dtype = int)\n",
        "    OperatingSystems = np.array(evidence['OperatingSystems'], dtype = int)\n",
        "    Browser = np.array(evidence['Browser'], dtype = int)\n",
        "    Region = np.array(evidence['Region'], dtype = int)\n",
        "    TrafficType = np.array(evidence['TrafficType'], dtype = int)\n",
        "    VisitorType = np.array(evidence['VisitorType'], dtype = int)\n",
        "    Weekend = np.array(evidence['Weekend'], dtype = int)\n",
        "    \n",
        "    evidence = np.array([Administrative, Administrative_Duration, Informational,Informational_Duration, ProductRelated, ProductRelated_Duration, BounceRates, ExitRates, PageValues, SpecialDay, Month, OperatingSystems, Browser, Region, TrafficType, VisitorType, Weekend], dtype = object).T.tolist()\n",
        "    \n",
        "    labels = df['Revenue'].tolist()\n",
        "    \n",
        "    return (evidence, labels)\n",
        "    raise NotImplementedError"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr9sSz_Qg2HA"
      },
      "source": [
        "# function to train model\n",
        "\n",
        "def train_model(X_train, y_train):\n",
        "   \n",
        "    from sklearn.neighbors import KNeighborsClassifier\n",
        "    model = KNeighborsClassifier(n_neighbors = 1)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    return model\n",
        "    raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3R3STPIg2Me"
      },
      "source": [
        "# function to evaluate model\n",
        "\n",
        "def evaluate(y_test, predictions):    \n",
        "   \n",
        "    from sklearn.metrics import confusion_matrix\n",
        "    result = confusion_matrix(y_test, predictions)\n",
        "    specificity= result[0,0]/(result[0,0]+result[1,0])\n",
        "    sensitivity= result[1,1]/(result[1,1]+result[0,1])\n",
        "    return sensitivity,specificity\n",
        "    \n",
        "    raise NotImplementedError"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsslVOwWg167"
      },
      "source": [
        "#defining test size\n",
        "\n",
        "TEST_SIZE = 0.4"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWAII7A7g2Pa"
      },
      "source": [
        "# Calling the Main Function\n",
        "\n",
        "main(TEST_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCd7PtNxjNxv"
      },
      "source": [
        "### **Recorded results after every run**\n",
        "\n",
        " \n",
        "### **First run**\n",
        "\n",
        " Correct: 4070\n",
        "\n",
        "Incorrect: 862\n",
        "\n",
        "True Positive Rate: 46.28%\n",
        "\n",
        "True Negative Rate: 87.98%\n",
        "\n",
        "\n",
        "### **Second run**\n",
        "\n",
        "Correct: 4116\n",
        "    \n",
        "Incorrect: 816\n",
        "    \n",
        "True Positive Rate: 44.33%\n",
        "    \n",
        "True Negative Rate: 89.70%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaAoUbmGg2Fd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFq9iZJNdlDC"
      },
      "source": [
        "**Thank You!!!**\n",
        "\n",
        "This project was done by\n",
        "\n",
        "Jash Bhtaia\n",
        "\n",
        "J007\n",
        "\n",
        "B.Tech Data Science 3rd year"
      ]
    }
  ]
}